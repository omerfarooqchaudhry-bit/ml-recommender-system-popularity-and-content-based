{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6337a690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 1571: ',' expected after '\"'\n",
      "Skipping line 4514: ',' expected after '\"'\n",
      "Skipping line 9967: ',' expected after '\"'\n",
      "Skipping line 10870: ',' expected after '\"'\n",
      "Skipping line 3349: Expected 12 fields in line 3349, saw 13\n",
      "Skipping line 4702: Expected 12 fields in line 4702, saw 13\n",
      "Skipping line 5877: Expected 12 fields in line 5877, saw 13\n",
      "Skipping line 8979: Expected 12 fields in line 8979, saw 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET        bookID                                              title  \\\n",
      "0           1  Harry Potter and the Half-Blood Prince (Harry ...   \n",
      "1           2  Harry Potter and the Order of the Phoenix (Har...   \n",
      "2           4  Harry Potter and the Chamber of Secrets (Harry...   \n",
      "3           5  Harry Potter and the Prisoner of Azkaban (Harr...   \n",
      "4           8  Harry Potter Boxed Set  Books 1-5 (Harry Potte...   \n",
      "...       ...                                                ...   \n",
      "11114   45631   Expelled from Eden: A William T. Vollmann Reader   \n",
      "11115   45633                        You Bright and Risen Angels   \n",
      "11116   45634                    The Ice-Shirt (Seven Dreams #1)   \n",
      "11117   45639                                        Poor People   \n",
      "11118   45641                        Las aventuras de Tom Sawyer   \n",
      "\n",
      "                                                 authors  average_rating  \\\n",
      "0                             J.K. Rowling/Mary GrandPré            4.57   \n",
      "1                             J.K. Rowling/Mary GrandPré            4.49   \n",
      "2                                           J.K. Rowling            4.42   \n",
      "3                             J.K. Rowling/Mary GrandPré            4.56   \n",
      "4                             J.K. Rowling/Mary GrandPré            4.78   \n",
      "...                                                  ...             ...   \n",
      "11114  William T. Vollmann/Larry McCaffery/Michael He...            4.06   \n",
      "11115                                William T. Vollmann            4.08   \n",
      "11116                                William T. Vollmann            3.96   \n",
      "11117                                William T. Vollmann            3.72   \n",
      "11118                                         Mark Twain            3.91   \n",
      "\n",
      "             isbn         isbn13 language_code    num_pages  ratings_count  \\\n",
      "0      0439785960  9780439785969           eng          652        2095690   \n",
      "1      0439358078  9780439358071           eng          870        2153167   \n",
      "2      0439554896  9780439554893           eng          352           6333   \n",
      "3      043965548X  9780439655484           eng          435        2339585   \n",
      "4      0439682584  9780439682589           eng         2690          41428   \n",
      "...           ...            ...           ...          ...            ...   \n",
      "11114  1560254416  9781560254416           eng          512            156   \n",
      "11115  0140110879  9780140110876           eng          635            783   \n",
      "11116  0140131965  9780140131963           eng          415            820   \n",
      "11117  0060878827  9780060878825           eng          434            769   \n",
      "11118  8497646983  9788497646987           spa          272            113   \n",
      "\n",
      "       text_reviews_count publication_date        publisher  \n",
      "0                   27591        9/16/2006  Scholastic Inc.  \n",
      "1                   29221         9/1/2004  Scholastic Inc.  \n",
      "2                     244        11/1/2003       Scholastic  \n",
      "3                   36325         5/1/2004  Scholastic Inc.  \n",
      "4                     164        9/13/2004       Scholastic  \n",
      "...                   ...              ...              ...  \n",
      "11114                  20       12/21/2004    Da Capo Press  \n",
      "11115                  56        12/1/1988    Penguin Books  \n",
      "11116                  95         8/1/1993    Penguin Books  \n",
      "11117                 139        2/27/2007             Ecco  \n",
      "11118                  12        5/28/2006    Edimat Libros  \n",
      "\n",
      "[11119 rows x 12 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11119 entries, 0 to 11118\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   bookID              11119 non-null  int64  \n",
      " 1   title               11119 non-null  object \n",
      " 2   authors             11119 non-null  object \n",
      " 3   average_rating      11119 non-null  float64\n",
      " 4   isbn                11119 non-null  object \n",
      " 5   isbn13              11119 non-null  int64  \n",
      " 6   language_code       11119 non-null  object \n",
      " 7     num_pages         11119 non-null  int64  \n",
      " 8   ratings_count       11119 non-null  int64  \n",
      " 9   text_reviews_count  11119 non-null  int64  \n",
      " 10  publication_date    11119 non-null  object \n",
      " 11  publisher           11119 non-null  object \n",
      "dtypes: float64(1), int64(5), object(6)\n",
      "memory usage: 1.0+ MB\n",
      "DATASET INFO None\n",
      "\n",
      "TOP 5 BY AVERAGE RATINGS\n",
      "       bookID                                              title  \\\n",
      "624     2034  Comoediae 1: Acharenses/Equites/Nubes/Vespae/P...   \n",
      "9891   39829  His Princess Devotional: A Royal Encounter Wit...   \n",
      "4786   17224  The Diamond Color Meditation: Color Pathway to...   \n",
      "9322   36853                 Tyrannosaurus Wrecks (Stanley  #1)   \n",
      "9718   38804      The Irish Anatomist: A Study of Flann O'Brien   \n",
      "\n",
      "                                                authors  average_rating  \\\n",
      "624                 Aristophanes/F.W. Hall/W.M. Geldart             5.0   \n",
      "9891                                Sheri Rose Shepherd             5.0   \n",
      "4786                                      John  Diamond             5.0   \n",
      "9322  Laura Driscoll/Alisa Klayman-Grodsky/Eric     ...             5.0   \n",
      "9718                                      Keith Donohue             5.0   \n",
      "\n",
      "            isbn         isbn13 language_code    num_pages  ratings_count  \\\n",
      "624   0198145047  9780198145042           grc          364              0   \n",
      "9891  1590529626  9781590529621           eng          240              2   \n",
      "4786  1890995525  9781890995522           eng           74              5   \n",
      "9322  0786845031  9780786845033           eng           24              2   \n",
      "9718  1930901356  9781930901353           eng          222              1   \n",
      "\n",
      "      text_reviews_count publication_date                     publisher  \n",
      "624                    0        2/22/1922  Oxford University Press  USA  \n",
      "9891                   0       10/16/2007                     Multnomah  \n",
      "4786                   3         2/1/2006         Square One Publishers  \n",
      "9322                   1         2/1/2003                  Disney Press  \n",
      "9718                   0        7/25/2003               Academica Press  \n",
      "\n",
      "TOP 5 BY RATINGS COUNT\n",
      "        bookID                                              title  \\\n",
      "10333   41865                            Twilight (Twilight  #1)   \n",
      "1696     5907                The Hobbit  or There and Back Again   \n",
      "1462     5107                             The Catcher in the Rye   \n",
      "307       960               Angels & Demons (Robert Langdon  #1)   \n",
      "3           5  Harry Potter and the Prisoner of Azkaban (Harr...   \n",
      "\n",
      "                          authors  average_rating        isbn         isbn13  \\\n",
      "10333             Stephenie Meyer            3.59  0316015849  9780316015844   \n",
      "1696               J.R.R. Tolkien            4.27  0618260307  9780618260300   \n",
      "1462                J.D. Salinger            3.80  0316769177  9780316769174   \n",
      "307                     Dan Brown            3.89  1416524797  9781416524793   \n",
      "3      J.K. Rowling/Mary GrandPré            4.56  043965548X  9780439655484   \n",
      "\n",
      "      language_code    num_pages  ratings_count  text_reviews_count  \\\n",
      "10333           eng          501        4597666               94265   \n",
      "1696            eng          366        2530894               32871   \n",
      "1462            eng          277        2457092               43499   \n",
      "307             eng          736        2418736               21303   \n",
      "3               eng          435        2339585               36325   \n",
      "\n",
      "      publication_date                  publisher  \n",
      "10333         9/6/2006  Little  Brown and Company  \n",
      "1696         8/15/2002           Houghton Mifflin  \n",
      "1462         1/30/2001             Back Bay Books  \n",
      "307           4/1/2006               Pocket Books  \n",
      "3             5/1/2004            Scholastic Inc.  \n",
      "\n",
      "COLUMNS\n",
      "Index(['bookID', 'title', 'authors', 'average_rating', 'isbn', 'isbn13',\n",
      "       'language_code', '  num_pages', 'ratings_count', 'text_reviews_count',\n",
      "       'publication_date', 'publisher'],\n",
      "      dtype='object')\n",
      "\n",
      "POPULARITY RECOMMENDER - TOP 5\n",
      "      bookID                                              title  \\\n",
      "3          5  Harry Potter and the Prisoner of Azkaban (Harr...   \n",
      "0          1  Harry Potter and the Half-Blood Prince (Harry ...   \n",
      "1          2  Harry Potter and the Order of the Phoenix (Har...   \n",
      "4414   15881  Harry Potter and the Chamber of Secrets (Harry...   \n",
      "23        34  The Fellowship of the Ring (The Lord of the Ri...   \n",
      "\n",
      "                         authors  average_rating        isbn         isbn13  \\\n",
      "3     J.K. Rowling/Mary GrandPré            4.56  043965548X  9780439655484   \n",
      "0     J.K. Rowling/Mary GrandPré            4.57  0439785960  9780439785969   \n",
      "1     J.K. Rowling/Mary GrandPré            4.49  0439358078  9780439358071   \n",
      "4414  J.K. Rowling/Mary GrandPré            4.42  0439064864  9780439064866   \n",
      "23                J.R.R. Tolkien            4.36  0618346252  9780618346257   \n",
      "\n",
      "     language_code    num_pages  ratings_count  text_reviews_count  \\\n",
      "3              eng          435        2339585               36325   \n",
      "0              eng          652        2095690               27591   \n",
      "1              eng          870        2153167               29221   \n",
      "4414           eng          341        2293963               34692   \n",
      "23             eng          398        2128944               13670   \n",
      "\n",
      "     publication_date                                 publisher  \\\n",
      "3            5/1/2004                           Scholastic Inc.   \n",
      "0           9/16/2006                           Scholastic Inc.   \n",
      "1            9/1/2004                           Scholastic Inc.   \n",
      "4414         6/2/1999  Arthur A. Levine Books / Scholastic Inc.   \n",
      "23           9/5/2003                 Houghton Mifflin Harcourt   \n",
      "\n",
      "      weighted_rating  \n",
      "3            4.187125  \n",
      "0            4.174501  \n",
      "1            4.147808  \n",
      "4414         4.128234  \n",
      "23           4.096698  \n",
      "Sample author description J.K. Rowling/Mary GrandPré\n",
      "tfidf_matrix <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 38637 stored elements and shape (11119, 8445)>\n",
      "  Coords\tValues\n",
      "  (0, 6581)\t0.5771265855737906\n",
      "  (0, 4988)\t0.44553176567161423\n",
      "  (0, 2937)\t0.684416795528479\n",
      "  (1, 6581)\t0.5771265855737906\n",
      "  (1, 4988)\t0.44553176567161423\n",
      "  (1, 2937)\t0.684416795528479\n",
      "  (2, 6581)\t1.0\n",
      "  (3, 6581)\t0.5771265855737906\n",
      "  (3, 4988)\t0.44553176567161423\n",
      "  (3, 2937)\t0.684416795528479\n",
      "  (4, 6581)\t0.5771265855737906\n",
      "  (4, 4988)\t0.44553176567161423\n",
      "  (4, 2937)\t0.684416795528479\n",
      "  (5, 2572)\t0.6100855468882519\n",
      "  (5, 8338)\t0.7923355510628453\n",
      "  (6, 6581)\t1.0\n",
      "  (7, 1982)\t0.6686357131320497\n",
      "  (7, 38)\t0.7435901311370365\n",
      "  (8, 1982)\t0.6686357131320497\n",
      "  (8, 38)\t0.7435901311370365\n",
      "  (9, 1982)\t0.6686357131320497\n",
      "  (9, 38)\t0.7435901311370365\n",
      "  (10, 1982)\t0.4388090358257461\n",
      "  (10, 38)\t0.4879997614326396\n",
      "  (10, 7272)\t0.3524665709916031\n",
      "  :\t:\n",
      "  (11111, 552)\t0.415874808368732\n",
      "  (11111, 2352)\t0.44908658820257463\n",
      "  (11111, 525)\t0.44908658820257463\n",
      "  (11112, 4533)\t0.3138873688130001\n",
      "  (11112, 203)\t0.415874808368732\n",
      "  (11112, 5945)\t0.39014545982406973\n",
      "  (11112, 552)\t0.415874808368732\n",
      "  (11112, 2352)\t0.44908658820257463\n",
      "  (11112, 525)\t0.44908658820257463\n",
      "  (11113, 8113)\t0.478532070872956\n",
      "  (11113, 7886)\t0.8780700753049498\n",
      "  (11114, 8113)\t0.23965404582536384\n",
      "  (11114, 5277)\t0.25055580231585034\n",
      "  (11114, 4380)\t0.37827551287430666\n",
      "  (11114, 7886)\t0.4397470073032584\n",
      "  (11114, 5085)\t0.5212091394886047\n",
      "  (11114, 3299)\t0.5212091394886047\n",
      "  (11115, 8113)\t0.478532070872956\n",
      "  (11115, 7886)\t0.8780700753049498\n",
      "  (11116, 8113)\t0.478532070872956\n",
      "  (11116, 7886)\t0.8780700753049498\n",
      "  (11117, 8113)\t0.478532070872956\n",
      "  (11117, 7886)\t0.8780700753049498\n",
      "  (11118, 4947)\t0.6001701587039222\n",
      "  (11118, 7744)\t0.7998723526921709\n",
      "TF-IDF Matrix Shape: 11119 Rows (Documents) x 8445 Columns (Terms or words or author description or their names)\n",
      "Total Documents/Books: 11119\n",
      "Total Vocabulary Size of authors data: 8445\n",
      "\n",
      "vector representing the importance of the words in the document/author description.\n",
      "TF-IDF Matrix <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 3 stored elements and shape (1, 8445)>\n",
      "  Coords\tValues\n",
      "  (0, 6581)\t0.5771265855737906\n",
      "  (0, 4988)\t0.44553176567161423\n",
      "  (0, 2937)\t0.684416795528479\n",
      "--- Analysis of Document 1 ---\n",
      "Vector Type: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Shape of this row: (1, 8445) (1 row across all vocabulary columns)\n",
      "Non-zero scores in this doc: 3\n",
      "Raw Vector Data:\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 3 stored elements and shape (1, 8445)>\n",
      "  Coords\tValues\n",
      "  (0, 6581)\t0.5771265855737906\n",
      "  (0, 4988)\t0.44553176567161423\n",
      "  (0, 2937)\t0.684416795528479\n",
      "\n",
      "Distance Matrix object type\n",
      "distance_matrix_type <class 'numpy.ndarray'>\n",
      "\n",
      "Distance Matrix Size\n",
      "123632161\n",
      "\n",
      "Distance Matrix Shape\n",
      "(11119, 11119)\n",
      "\n",
      "RECOMMENDATIONS\n",
      "6974                                   Eric A. Meyer\n",
      "3684                                     Joyce Meyer\n",
      "8778                                   Carolyn Meyer\n",
      "9257                                   Carolyn Meyer\n",
      "9258                                   Carolyn Meyer\n",
      "9259                                   Carolyn Meyer\n",
      "9260                                   Carolyn Meyer\n",
      "3087                Sinclair Lewis/Michael R.  Meyer\n",
      "90      Leo Tolstoy/David Magarshack/Priscilla Meyer\n",
      "1316        Gabriel García Márquez/Curt Meyer-Clason\n",
      "Name: authors, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Recommender System\n",
    "Requirements:\n",
    "A dataset of books from Goodreads known for use in recommendation engines.\n",
    "Columns Description:\n",
    "bookID contains the unique ID for each book/series\n",
    "title contains the titles of the books\n",
    "authors contains the author of the particular book\n",
    "average_rating the average rating of the books, as decided by the users\n",
    "ISBNISBN (10) number, tells the information about a book - such as edition and publisher\n",
    "ISBN 13 the new format for ISBN, implemented in 2007 (13 digits)\n",
    "language_code denotes the language for the books\n",
    "Num_pages contains the number of pages for the book\n",
    "Ratings_count contains the number of ratings given for the book\n",
    "text_reviews_count the count of reviews left by users\n",
    "Expected Output\n",
    "By the end of this mini project, you are supposed to deliver within your code:\n",
    "Multiple recommendations based on the implementation of two different recommendation engine:\n",
    "Popularity based recommender.\n",
    "Content based recommender.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    import pandas as pd\n",
    "    \n",
    "    # STEP 1 & 2: Download and read the Dataset \n",
    "    df = pd.read_csv('books.csv', engine='python', on_bad_lines='warn')    \n",
    "    print(\"DATASET\", df)\n",
    "    print(\"DATASET INFO\", df.info())\n",
    "\n",
    "    # STEP 3 Popularity-based Recommender\n",
    "    \"\"\"\n",
    "    Popularity-based Recommender\n",
    "    Create a function named Popularity Recommender and use it to recommend books based on popularity.\n",
    "    Use a weighted rank similar to that used in the IMDB rating example in Lesson 2.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" find the five highest ranked books in the dataset by average_rating\"\"\"\n",
    "    print(\"\\nTOP 5 BY AVERAGE RATINGS\")\n",
    "    top5Recommendations = df.sort_values(by = 'average_rating',\n",
    "                                     ascending = False).head(5)\n",
    "    print(\"\", top5Recommendations)\n",
    "\n",
    "    \"\"\" find the five highest ranked books in the dataset by ratings_count \"\"\"\n",
    "    print(\"\\nTOP 5 BY RATINGS COUNT\")\n",
    "    top5Recommendations = df.sort_values(by = 'ratings_count',\n",
    "                                     ascending = False).head(5)\n",
    "    print(\"\", top5Recommendations)\n",
    "\n",
    "    \"\"\"\n",
    "    Create a function named Popularity Recommender and use it to recommend books based on popularity.\n",
    "    Use a weighted rank similar to that used in the IMDB rating example in Lesson 2.\n",
    "    \"\"\"\n",
    "    print(\"\\nCOLUMNS\")\n",
    "    print(df.columns)\n",
    "\n",
    "    def popularityRecommender(df):\n",
    "    \n",
    "        #Define the minimum ratings count\n",
    "        minimum_vote_count = 0.75 * df['ratings_count'].max()\n",
    "        \n",
    "        #Define C – the mean rating\n",
    "        mean_rating = df['average_rating'].mean()\n",
    "\n",
    "        df['weighted_rating'] = (((df['ratings_count']/(df['ratings_count']+minimum_vote_count)) * df['average_rating']) +\n",
    "                                ((minimum_vote_count/(df['ratings_count']+minimum_vote_count))*mean_rating))\n",
    "\n",
    "        recommendations = df.sort_values(by = 'weighted_rating',ascending = False).head(5)\n",
    "        \n",
    "        return(recommendations) \n",
    "\n",
    "    print(\"\\nPOPULARITY RECOMMENDER - TOP 5\")\n",
    "    top5 = popularityRecommender(df)\n",
    "    top5[[\"title\",'ratings_count','average_rating','weighted_rating',]].head(5)\n",
    "    print(top5)\n",
    "\n",
    "    \n",
    "    # STEP 4 Content-based Recommender\n",
    "    # So what we're doing in our content based recommender:\n",
    "    # we're converting words in some Document into a vector\n",
    "    # ignore stop words.\n",
    "    # We count up all the words across all the authors descriptions.\n",
    "    # then calculate the occurrence of each word and each document/author name (TF)\n",
    "    # That's the term frequency and multiply it by the number of documents with each word. That's the inverse document frequency, and then we end up with an N dimensional vector for each document represented by.\n",
    "    # The length being the number of unique words that we're working with in the whole library. So then.\n",
    "    # We multiply those two terms together and that gives us the TFI TFIDF normalised vector\n",
    "    # This is the cosine similarity. So this is a distance calculation to determine the angle of separation between.\n",
    "    # In each vector. So between each pair of vectors in our N dimensional, so N words dimensional space\n",
    "    # basically we want to find the words that are the most similar. Lowest cosine because cosine gets gets lower as angle decreases\n",
    "    # 0 is the same 1 is opposite or no similarity\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ITEM to ITEM COMPARISON\n",
    "    Content-based Recommender\n",
    "    Create a function named Content-based Recommender and use it to recommend books based on content.\n",
    "    TF-IDF Vectorizer\n",
    "    Use TF-IDF Vectorizer on the author data for each book.\n",
    "    Distance matrix\n",
    "    Choose cosine similarity for pairwise distances comparison.\n",
    "    -------------------------------------------------------\n",
    "    Recommender system, content based recommender item to item comparison does not take into account how people have viewed or interacted with it.\n",
    "    None of that is considered here. We are just looking at what describes our item and finding similar items. So at the end of the day, if I watch.\n",
    "    Harry Potter. Maybe it gives me fantastical beasts next or some other fantasy show, right?\n",
    "    Even better, if it's like a magic oriented one, 'cause, that's kind of what that's about.\n",
    "    We need text to describe my items. in this case author names\n",
    "    Scalar output per word in our document(author description)\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "    # Replace empty descriptions with a blank \"\" value and transform the author of books in our dataset into the TF-IDF matrix\n",
    "\n",
    "    \"\"\"\n",
    "    So essentially what we're doing is we're taking\n",
    "    all of the words for our documents and using that to create a sparse vector that represents our items. So that's why it's called. It's the TFIDF vectorizer. We can make an instance of our vectorizer.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "    print(\"Sample author description\", df['authors'][0])\n",
    "    df['authors'] = df['authors'].fillna('')\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['authors'])\n",
    "    print(\"tfidf_matrix\", tfidf_matrix)\n",
    "    \"\"\"    \n",
    "    How often the term, whatever the word (author name ?), whatever the term, is typically a word. So how often a word occurs in the particular document that I'm looking at and it's basically. \n",
    "    The frequency because I'm dividing that by the total number of terms or words in the document. \n",
    "    So if I have a sentence, the cat is hungry.\n",
    "    Let's do five `the black cat is hungry`, then each one of those would occur 1/5 of the time because there's no duplicated words. If I said the hungry cat is hungry, then hungry becomes a more important term in that document because it's occurring twice out of those 5 words. So it's going to have a higher frequency.\n",
    "    And then there's a second term to this. So this is the inverse document frequency and what we need to do is count the documents(authors or theor names). So the total number of documents that I'm considering in my analysis.\n",
    "    So my sentence had five words. Maybe I have 100 sentences, so that would be 100 and we need to compare that term through the documents. So how many times does the word hungry occur in all of my sentences?\n",
    "    Maybe it's in four other sentences. There's a hungry dog and a hungry person and a hungry cat. Again, I don't know. So of my 100 documents, it occurs four times and I take the log of that. So this is essentially a method to give higher weightings to those rare words.\n",
    "\n",
    "    Our TFIDF vectorizer is going to take in the first sentence(author) and calculate.\n",
    "    TFIDF value for every word in this sentence.\n",
    "    Except for the stop words. So let's check. I use this Lambda function to split up my words so there is actually 50 words in this sentence\n",
    "\n",
    "    \"\"\"\n",
    "    rows, cols = tfidf_matrix.shape\n",
    "\n",
    "    print(f\"TF-IDF Matrix Shape: {rows} Rows (Documents) x {cols} Columns (Terms or words or author description or their names)\")\n",
    "    print(f\"Total Documents/Books: {rows}\")\n",
    "    print(f\"Total Vocabulary Size of authors data: {cols}\")\n",
    "\n",
    "    # There are 8445 words used to describe the different authors and will those words in the similarity analysis\n",
    "    # Look at the vector representing the importance of the words in the document. Cumulatively, they represent the document/author description.\n",
    "    # For book zero columns 6581 the TFIDF value for that word is 0.5771265855737906\n",
    "    # For book zero columns 4988 the TFIDF value for that word is 0.44553176567161423\n",
    "    # For book zero columns 2937 the TFIDF value for that word is 0.684416795528479       \n",
    "    print(\"\\nvector representing the importance of the words in the document/author description.\")\n",
    "    print(\"TF-IDF Matrix\", tfidf_matrix[0])\n",
    "\n",
    "    \"\"\"\n",
    "    So what we have here is essentially a vector. Now in N dimensional space that represents the book, The Catcher in the Rye and so.\n",
    "    we ctually have a vector of this size for every single book  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the first row\n",
    "    first_doc_vector = tfidf_matrix[0]\n",
    "    print(f\"--- Analysis of Document 1 ---\")\n",
    "    print(f\"Vector Type: {type(first_doc_vector)}\")\n",
    "    print(f\"Shape of this row: {first_doc_vector.shape} (1 row across all vocabulary columns)\")\n",
    "    print(f\"Non-zero scores in this doc: {first_doc_vector.nnz if hasattr(first_doc_vector, 'nnz') else 'N/A'}\")\n",
    "    print(f\"Raw Vector Data:\\n{first_doc_vector}\")\n",
    "\n",
    "    # Assign the instance of our recommender function.\n",
    "    # This is a matrix with a similarity value for every book with every other book in the dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    cosine similarity and basically what we're doing is we're finding the angle of separation between 2 book vectors you could also say this is the dot product between the two vectors and the resulting scalar singular value is basically a representation of the similarity between those two.\n",
    "    items for busines   \n",
    "    We call these processes pairwise processes, because we're trying, we're basically making every possible computation of two pairs of things, and then calculating a similarity value. We'll use cosine similarity. \n",
    "    Cosign similarity is the most common \n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    distance_matrix = cosine_similarity(tfidf_matrix)\n",
    "    print(\"\\nDistance Matrix object type\")\n",
    "    print(\"distance_matrix_type\", type(distance_matrix))\n",
    "\n",
    "    # Re-create the indices of our list of books by removing any duplicates if required\n",
    "    indices = pd.Series(df.index, index=df['authors']).drop_duplicates()\n",
    "    print(\"\\nDistance Matrix Size\")\n",
    "    print(distance_matrix.size)\n",
    "    print(\"\\nDistance Matrix Shape\")\n",
    "    print(distance_matrix.shape)\n",
    "\n",
    "    # Define a function that takes the re-indexed dataset, finds the 6 most similar authors/their names or descriptions \n",
    "    #to a chosen author based on the\n",
    "    # similarity of the words in the authors,\n",
    "    # and returns the top 10, (not) including itself, which will be the best match. \n",
    "\n",
    "    def ContentBasedRecommender(authors, indices, distance_matrix):\n",
    "        id_ = indices[authors] #Fetch the index of the book we will enter\n",
    "        \n",
    "        #List of tuples with distance for each book to the entered book (2 cols = id and distance)\n",
    "        distances = list(enumerate(distance_matrix[id_]))\n",
    "        \n",
    "        #sort by the distance function, which is in column[1]\n",
    "        distances = sorted(distances, key=lambda x: x[1], reverse = True)\n",
    "        \n",
    "        distances = distances[1:11] # Get the 10 best scores , not including itself\n",
    "        \n",
    "        # get the indices of the top 10\n",
    "        recommendations = [distance[0] for distance in distances]\n",
    "        \n",
    "        # return those recommendation names by pulling authors from the given 10 indices\n",
    "        return df['authors'].iloc[recommendations]\n",
    "   \n",
    "    recommendations = ContentBasedRecommender(\"Stephenie Meyer\", indices, distance_matrix)\n",
    "    \n",
    "    print(\"\\nRECOMMENDATIONS\")\n",
    "    print(recommendations)    \n",
    "  \n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
